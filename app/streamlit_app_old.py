import streamlit as st
from openai import OpenAI
import json
import numpy as np
import os
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions
import datetime
# Load environment variables
load_dotenv()
client = OpenAI()

# Connect to upgraded article-based Chroma DB
embed_func = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="intfloat/multilingual-e5-large"
)

chroma_client = chromadb.PersistentClient(
    path=r"C:\Users\PC\OneDrive\Desktop\chatbot\data\chroma_db_articles"
)

collection = chroma_client.get_collection(
    name="penal_code_articles",
    embedding_function=embed_func
)


# Load chunks (optional for display)
with open(r"C:\Users\PC\OneDrive\Desktop\chatbot\data\processed\penal_code_chunks.json", "r", encoding="utf-8") as f:
    chunks = json.load(f)

# --- Helper: retrieve context ---
def retrieve_context(query: str, top_k: int = 3):
    """Retrieve top_k articles + metadata for a user query from Chroma."""
    res = collection.query(
        query_texts=[query],
        n_results=top_k,
        include=["documents", "metadatas", "distances"]
    )
    docs = res["documents"][0]
    metas = res["metadatas"][0]
    dists = res["distances"][0]
    sims = [1 - d for d in dists]
    return list(zip(docs, metas, sims))

# --- Helper: build prompt ---
def build_prompt_ar(question, context_block):
    return (
        f"Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ø¹ØªÙ…Ø§Ø¯Ø§Ù‹ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©.\n\n"
        f"Ø§Ù„Ø³Ø¤Ø§Ù„: {question}\n\n"
        f"Ø§Ù„Ù†ØµÙˆØµ:\n{context_block}\n\n"
        "Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ø§Ø®ØªØµØ§Ø±ØŒ Ù…Ø¹ Ø°ÙƒØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø¯Ø§Ø®Ù„ Ø£Ù‚ÙˆØ§Ø³ Ù…Ø±Ø¨Ø¹Ø©."
    )

# --- Streamlit layout ---
st.set_page_config(page_title="AI Legal Chatbot â€“ Lebanese Law", layout="wide")
st.title("âš–ï¸ AI Legal Chatbot â€“ Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠ")

question = st.text_area("âœï¸ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù‡Ù†Ø§:", placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø±Ù‚Ø©ØŸ")

if st.button("ğŸ” Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"):
    if not question.strip():
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„.")
    else:
        # Retrieve relevant context
        results = retrieve_context(question, top_k=3)
        ctx = "\n\n".join([f"[{cid}] {doc}" for cid, _, doc in results])
        prompt = build_prompt_ar(question, ctx)

        # Generate answer
        with st.spinner("Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ..."):
            response = client.chat.completions.create(
                model="gpt-4o-mini",  # or gpt-4o
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
        answer = response.choices[0].message.content

        # --- Display answer ---
        st.subheader("ğŸ§¾ Ø§Ù„Ø¬ÙˆØ§Ø¨:")
        st.write(answer)

        with st.expander("ğŸ“š Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"):
            for doc, meta, sim in results:
                art = meta.get("article", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©")
                st.markdown(f"**Ø§Ù„Ù…Ø§Ø¯Ø© {art}**  |  ØªØ´Ø§Ø¨Ù‡: {sim:.2f}")
                st.write(doc[:1200] + ("â€¦" if len(doc) > 1200 else ""))
                st.divider()
        # --- Feedback Section ---
        st.subheader("ğŸ—³ï¸ Ù‡Ù„ ÙƒØ§Ù†Øª Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙÙŠØ¯Ø©ØŸ")
        col1, col2 = st.columns(2)

        if "feedback_given" not in st.session_state:
            st.session_state["feedback_given"] = False

        if col1.button("ğŸ‘ Ù†Ø¹Ù…", disabled=st.session_state["feedback_given"]):
            st.session_state["feedback_given"] = True
            feedback = {"question": question, "answer": answer, "helpful": True, "timestamp": datetime.datetime.now().isoformat()}
            with open("feedback.json", "a", encoding="utf-8") as f:
                f.write(json.dumps(feedback, ensure_ascii=False) + "\n")
                st.success("âœ… Ø´ÙƒØ±Ø§Ù‹! ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ù„Ø§Ø­Ø¸ØªÙƒ.")

        if col2.button("ğŸ‘ Ù„Ø§", disabled=st.session_state["feedback_given"]):
            st.session_state["feedback_given"] = True
            feedback = {"question": question, "answer": answer, "helpful": False, "timestamp": datetime.datetime.now().isoformat()}
            with open("feedback.json", "a", encoding="utf-8") as f:
                f.write(json.dumps(feedback, ensure_ascii=False) + "\n")
            st.warning("ğŸ“© ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ù„Ø§Ø­Ø¸ØªÙƒ. Ø³Ù†Ø¹Ù…Ù„ Ø¹Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.")
        # --- Log each interaction automatically ---
        log_entry = {
            "timestamp": datetime.datetime.now().isoformat(),
            "question": question,
            "answer": answer,
            "retrieved_articles": [meta.get("article") for _, meta, _ in results],
}   

        os.makedirs("logs", exist_ok=True)
        with open("logs/chat_logs.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

